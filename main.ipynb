{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masang/anaconda3/envs/torchenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocess_text\n",
    "import random\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.transformer import Transformer\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390804</th>\n",
       "      <td>극중에서 박중훈이 부른 노래 ‘비와 당신’은 음악 예능 프로그램 등에서 다시 불리며...</td>\n",
       "      <td>The song \"Rain and You\" sung by Park Joong-hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388723</th>\n",
       "      <td>음악을 들으면 들을수록 묘하게 빠져드는 리듬과 가사들이 평소 아이돌 노래에 관심도 ...</td>\n",
       "      <td>The rhythms and lyrics that fall strangely as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289681</th>\n",
       "      <td>매 작품마다 시청자들을 몰입시키는 강한 흡입력을 가진 임수향이 보여줄 드라마 ‘내 ...</td>\n",
       "      <td>Expectations are high the drama \"My ID is Gang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434982</th>\n",
       "      <td>과목별로 포트폴리오 활동과 다양한 논·서술형 등을 포함하고 있으며 수행평가 1개당 ...</td>\n",
       "      <td>It includes portfolio activities and various t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321428</th>\n",
       "      <td>당초 하남 감북지구가 유력하게 꼽혔으나 교산지구로 최종 낙점됐다.</td>\n",
       "      <td>Originally, Hanam Gambuk District was prominen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       원문  \\\n",
       "390804  극중에서 박중훈이 부른 노래 ‘비와 당신’은 음악 예능 프로그램 등에서 다시 불리며...   \n",
       "388723  음악을 들으면 들을수록 묘하게 빠져드는 리듬과 가사들이 평소 아이돌 노래에 관심도 ...   \n",
       "289681  매 작품마다 시청자들을 몰입시키는 강한 흡입력을 가진 임수향이 보여줄 드라마 ‘내 ...   \n",
       "434982  과목별로 포트폴리오 활동과 다양한 논·서술형 등을 포함하고 있으며 수행평가 1개당 ...   \n",
       "321428               당초 하남 감북지구가 유력하게 꼽혔으나 교산지구로 최종 낙점됐다.   \n",
       "\n",
       "                                                      번역문  \n",
       "390804  The song \"Rain and You\" sung by Park Joong-hoo...  \n",
       "388723  The rhythms and lyrics that fall strangely as ...  \n",
       "289681  Expectations are high the drama \"My ID is Gang...  \n",
       "434982  It includes portfolio activities and various t...  \n",
       "321428  Originally, Hanam Gambuk District was prominen...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = \"data/train_filtered.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_data_dir)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740073\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ko_text, processed_en_text = [], []\n",
    "\n",
    "for idx in range(len(train_df)):\n",
    "    processed_ko_text.append(preprocess_text(train_df[\"원문\"][idx], lang=\"ko\"))\n",
    "    processed_en_text.append(preprocess_text(train_df[\"번역문\"][idx], lang=\"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "ko_tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "print(ko_tokenizer.vocab_size)\n",
    "print(en_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ko_text, tokenized_en_text = [], []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    ko_tokens = ko_tokenizer.tokenize(processed_ko_text[i])\n",
    "    ko_seq = ko_tokenizer(processed_ko_text[i])\n",
    "    tokenized_ko_text.append(ko_seq[\"input_ids\"])\n",
    "\n",
    "    en_tokens = en_tokenizer.tokenize(processed_en_text[i])\n",
    "    en_seq = en_tokenizer(processed_en_text[i])\n",
    "    tokenized_en_text.append(en_seq[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_ID = 0  # 토크나이저 pad_token_id\n",
    "\n",
    "# tokenized_en_text: [[101, 2003, 102], [101, 1234, 5678, 102], ...]\n",
    "\n",
    "enc_train = pad_sequence(\n",
    "    [torch.tensor(seq) for seq in tokenized_ko_text],\n",
    "    batch_first=True,\n",
    "    padding_value=PAD_ID,\n",
    ")\n",
    "dec_train = pad_sequence(\n",
    "    [torch.tensor(seq) for seq in tokenized_en_text],\n",
    "    batch_first=True,\n",
    "    padding_value=PAD_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([740073, 60]) torch.Size([740073, 60])\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape, dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2,  3693,  2052,  3666, 17378,  2170,  7258,  2138,  6274,  2067,\n",
      "         3739, 17378,  3816,  2116, 10315,  2138,  1122,  2069,   575,  2052,\n",
      "         2241,  7450,  2052,  4763,  2205,  2259,   575,  6233,  7483,  2897,\n",
      "         2062,    18,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([  101,  2009,  2003, 10009,  2008,  2065,  2859, 17607,  2015, 26269,\n",
      "         2006,  1057,  1012,  1055,  1012,  7975,  2009,  2097,  5770,  4759,\n",
      "         7975,  3316,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "print(enc_train[1121])\n",
    "print(dec_train[1121])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 생성 및 디바이스 이동\n",
    "model = Transformer(\n",
    "    src_vocab_size=ko_tokenizer.vocab_size,\n",
    "    tgt_vocab_size=en_tokenizer.vocab_size,\n",
    "    src_len=60,  # 인코더 입력 길이\n",
    "    tgt_len=60,  # 디코더 입력 길이\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    n_heads=8,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=6,\n",
    "    dropout=0.3,\n",
    ").to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
