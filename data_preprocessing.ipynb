{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import preprocess_text\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>749730</th>\n",
       "      <td>그 벤치에서 두 사람이 이야기를 나누고 특히 조용한 독대를 하면서 마음을 다 열고 ...</td>\n",
       "      <td>It was noted that the two of them talked on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728687</th>\n",
       "      <td>지역 거주환자가 자신의 지역 의료기관을 이용하는 정도를 의미하는 ‘의료서비스 이용률...</td>\n",
       "      <td>The \"Medical Service Utilization Rate,\" which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684982</th>\n",
       "      <td>전임 김영기 총재가 밀어붙인 신장 제한 규정은 해외 토픽으로 소개될 만큼 국내외적으...</td>\n",
       "      <td>The height restrictions imposed by the former ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120168</th>\n",
       "      <td>지난해는 성남과 용인시의 자체사업으로 중학교 신입생에 대한 교복지원이 이루어지며 교...</td>\n",
       "      <td>Last year, Seongnam-si and Yongin-si's own pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511621</th>\n",
       "      <td>양주시의회와 동두천양주교육지원청이 공동 주최하고, 감동교육을 실천하는 100인 연대...</td>\n",
       "      <td>The Yangju Hope Education Forum, co-hosted by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       원문  \\\n",
       "749730  그 벤치에서 두 사람이 이야기를 나누고 특히 조용한 독대를 하면서 마음을 다 열고 ...   \n",
       "728687  지역 거주환자가 자신의 지역 의료기관을 이용하는 정도를 의미하는 ‘의료서비스 이용률...   \n",
       "684982  전임 김영기 총재가 밀어붙인 신장 제한 규정은 해외 토픽으로 소개될 만큼 국내외적으...   \n",
       "120168  지난해는 성남과 용인시의 자체사업으로 중학교 신입생에 대한 교복지원이 이루어지며 교...   \n",
       "511621  양주시의회와 동두천양주교육지원청이 공동 주최하고, 감동교육을 실천하는 100인 연대...   \n",
       "\n",
       "                                                      번역문  \n",
       "749730  It was noted that the two of them talked on th...  \n",
       "728687  The \"Medical Service Utilization Rate,\" which ...  \n",
       "684982  The height restrictions imposed by the former ...  \n",
       "120168  Last year, Seongnam-si and Yongin-si's own pro...  \n",
       "511621  The Yangju Hope Education Forum, co-hosted by ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/aihub_news_data.csv\"\n",
    "\n",
    "df = pd.read_csv(data_dir)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801387\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Korean Text: 경총은 “석유화학이나 철강업의 대정비, 조선업의 시운전, 건설업의 기상악화로 인한 공기 지연, 방송·영화 제작업의 인력 대체 불가능 등이 인가연장근로가 필요한 대표적인 사례”라고 주장했다.\n",
      "Processed Korean Text: 경총은 석유화학이나 철강업의 대정비 조선업의 시운전 건설업의 기상악화로 인한 공기 지연 방송 영화 제작업의 인력 대체 불가능 등이 인가연장근로가 필요한 대표적인 사례 라고 주장했다.\n",
      "Original English Text: The Korea Enterprises Federation claimed that such cases as large maintenance of the petrochemical or steel industry, the trial voyage of the shipbuilding industry, schedule delay caused by bad weather in the construction industry, and the inability to replace manpower in broadcasting and film production industries are the representative examples that require an extended working hour.\n",
      "Processed English Text: The Korea Enterprises Federation claimed that such cases as large maintenance of the petrochemical or steel industry the trial voyage of the shipbuilding industry schedule delay caused by bad weather in the construction industry and the inability to replace manpower in broadcasting and film production industries are the representative examples that require an extended working hour.\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(df) - 1)\n",
    "\n",
    "processed_ko_text = preprocess_text(df[\"원문\"][idx], lang=\"ko\")\n",
    "processed_en_text = preprocess_text(df[\"번역문\"][idx], lang=\"en\")\n",
    "\n",
    "print(\"Original Korean Text:\", df[\"원문\"][idx])\n",
    "print(\"Processed Korean Text:\", processed_ko_text)\n",
    "print(\"Original English Text:\", df[\"번역문\"][idx])\n",
    "print(\"Processed English Text:\", processed_en_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "ko_tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 텍스트: ['경총', '##은', '석유', '##화학', '##이나', '철강업', '##의', '대', '##정', '##비', '조선업', '##의', '시', '##운전', '건설업', '##의', '기상', '##악', '##화', '##로', '인한', '공기', '지연', '방송', '영화', '제작', '##업', '##의', '인력', '대체', '불가', '##능', '등', '##이', '인가', '##연', '##장', '##근', '##로', '##가', '필요', '##한', '대표', '##적인', '사례', '라고', '주장', '##했', '##다', '.']\n",
      "정수 인덱스로 변환된 토큰: [26479, 2073, 5728, 22563, 15351, 23719, 2079, 823, 2287, 2151, 15018, 2079, 1325, 10926, 12795, 2079, 7179, 2376, 2267, 2200, 5198, 5495, 7035, 3861, 3771, 4271, 2078, 2079, 4862, 4761, 5391, 2183, 886, 2052, 3955, 2156, 2121, 2169, 2200, 2116, 3677, 2470, 3661, 31221, 4411, 3609, 3831, 2371, 2062, 18]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 토큰화\n",
    "ko_tokens = ko_tokenizer.tokenize(processed_ko_text)\n",
    "print(\"토큰화된 텍스트:\", ko_tokens)\n",
    "\n",
    "# 토큰을 정수 인덱스로 변환\n",
    "ko_input_ids = ko_tokenizer.convert_tokens_to_ids(ko_tokens)\n",
    "print(\"정수 인덱스로 변환된 토큰:\", ko_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 텍스트: ['the', 'korea', 'enterprises', 'federation', 'claimed', 'that', 'such', 'cases', 'as', 'large', 'maintenance', 'of', 'the', 'pet', '##ro', '##chemical', 'or', 'steel', 'industry', 'the', 'trial', 'voyage', 'of', 'the', 'shipbuilding', 'industry', 'schedule', 'delay', 'caused', 'by', 'bad', 'weather', 'in', 'the', 'construction', 'industry', 'and', 'the', 'inability', 'to', 'replace', 'manpower', 'in', 'broadcasting', 'and', 'film', 'production', 'industries', 'are', 'the', 'representative', 'examples', 'that', 'require', 'an', 'extended', 'working', 'hour', '.']\n",
      "정수 인덱스로 변환된 토큰: [1996, 4420, 9926, 4657, 3555, 2008, 2107, 3572, 2004, 2312, 6032, 1997, 1996, 9004, 3217, 15869, 2030, 3886, 3068, 1996, 3979, 8774, 1997, 1996, 16802, 3068, 6134, 8536, 3303, 2011, 2919, 4633, 1999, 1996, 2810, 3068, 1998, 1996, 13720, 2000, 5672, 22039, 1999, 5062, 1998, 2143, 2537, 6088, 2024, 1996, 4387, 4973, 2008, 5478, 2019, 3668, 2551, 3178, 1012]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 토큰화\n",
    "en_tokens = en_tokenizer.tokenize(processed_en_text)\n",
    "print(\"토큰화된 텍스트:\", en_tokens)\n",
    "\n",
    "# 토큰을 정수 인덱스로 변환\n",
    "en_input_ids = en_tokenizer.convert_tokens_to_ids(en_tokens)\n",
    "print(\"정수 인덱스로 변환된 토큰:\", en_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 한국어 문장 길이 통계 (토큰 수 기준)\n",
      "- 평균: 34.17534474604654\n",
      "- 중앙값: 35.0\n",
      "- 표준편차: 11.193086731190547\n",
      "📊 영어 문장 길이 통계 (토큰 수 기준)\n",
      "- 평균: 32.65063945384689\n",
      "- 중앙값: 33.0\n",
      "- 표준편차: 12.090316986627746\n",
      "\n",
      "📌 한국어 문장 길이 상위 5% 임계값: 52.0\n",
      "\n",
      "📌 영어 문장 길이 상위 5% 임계값: 53.0\n"
     ]
    }
   ],
   "source": [
    "# 한국어 문장 길이 계산 (전처리 + 토크나이저 기준)\n",
    "ko_lengths = df['원문'].apply(lambda x: len(ko_tokenizer.tokenize(preprocess_text(str(x), lang=\"ko\"))))\n",
    "\n",
    "# 영어 문장 길이 계산 (전처리 + 토크나이저 기준)\n",
    "en_lengths = df['번역문'].apply(lambda x: len(en_tokenizer.tokenize(preprocess_text(str(x), lang=\"en\"))))\n",
    "\n",
    "# 전체 통계 출력\n",
    "print(\"📊 한국어 문장 길이 통계 (토큰 수 기준)\")\n",
    "print(\"- 평균:\", ko_lengths.mean())\n",
    "print(\"- 중앙값:\", ko_lengths.median())\n",
    "print(\"- 표준편차:\", ko_lengths.std())\n",
    "\n",
    "print(\"📊 영어 문장 길이 통계 (토큰 수 기준)\")\n",
    "print(\"- 평균:\", en_lengths.mean())\n",
    "print(\"- 중앙값:\", en_lengths.median())\n",
    "print(\"- 표준편차:\", en_lengths.std())\n",
    "\n",
    "# 상위 5% 기준 임계값\n",
    "ko_threshold = ko_lengths.quantile(0.95)\n",
    "en_threshold = en_lengths.quantile(0.95)\n",
    "\n",
    "# 상위 5%에 해당하는 샘플들의 길이\n",
    "ko_top5 = ko_lengths[ko_lengths >= ko_threshold]\n",
    "en_top5 = en_lengths[en_lengths >= en_threshold]\n",
    "\n",
    "print(f\"\\n📌 한국어 문장 길이 상위 5% 임계값: {ko_threshold}\")\n",
    "print(f\"\\n📌 영어 문장 길이 상위 5% 임계값: {en_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 한국어 데이터셋\n",
      "- 전체 토큰 수: 27387677\n",
      "- 고유 토큰 수: 29933\n",
      "\n",
      "📊 영어 데이터셋\n",
      "- 전체 토큰 수: 26165798\n",
      "- 고유 토큰 수: 26585\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_ko_tokens = []\n",
    "all_en_tokens = []\n",
    "\n",
    "# 모든 텍스트를 전처리하고 토큰화하여 리스트에 저장\n",
    "for text in df['원문']:\n",
    "    processed = preprocess_text(str(text), lang=\"ko\")\n",
    "    all_ko_tokens.extend(ko_tokenizer.tokenize(processed))\n",
    "\n",
    "for text in df['번역문']:\n",
    "    processed = preprocess_text(str(text), lang=\"en\")\n",
    "    all_en_tokens.extend(en_tokenizer.tokenize(processed))\n",
    "\n",
    "# 전체 토큰 수\n",
    "total_ko_tokens = len(all_ko_tokens)\n",
    "total_en_tokens = len(all_en_tokens)\n",
    "\n",
    "# 고유 토큰 수\n",
    "unique_ko_tokens = len(set(all_ko_tokens))\n",
    "unique_en_tokens = len(set(all_en_tokens))\n",
    "\n",
    "# 결과 출력\n",
    "print(\"📊 한국어 데이터셋\")\n",
    "print(\"- 전체 토큰 수:\", total_ko_tokens)\n",
    "print(\"- 고유 토큰 수:\", unique_ko_tokens)\n",
    "\n",
    "print(\"\\n📊 영어 데이터셋\")\n",
    "print(\"- 전체 토큰 수:\", total_en_tokens)\n",
    "print(\"- 고유 토큰 수:\", unique_en_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 KO 토큰 통계\n",
      "- 전체 토큰 수 (중복 포함): 27387677\n",
      "- 고유 토큰 수: 29933\n",
      "- 상위 95% 빈도를 커버하는 토큰 수: 9144\n",
      "📊 EN 토큰 통계\n",
      "- 전체 토큰 수 (중복 포함): 26165798\n",
      "- 고유 토큰 수: 26585\n",
      "- 상위 95% 빈도를 커버하는 토큰 수: 6522\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_vocab_cutoff(tokens, coverage=0.95, lang='ko'):\n",
    "    counter = Counter(tokens)\n",
    "    total_freq = sum(counter.values())\n",
    "    sorted_tokens = counter.most_common()\n",
    "    \n",
    "    cumulative = 0\n",
    "    cutoff = 0\n",
    "    \n",
    "    for i, (_, freq) in enumerate(sorted_tokens):\n",
    "        cumulative += freq\n",
    "        if cumulative / total_freq >= coverage:\n",
    "            cutoff = i + 1  # index가 0부터 시작하므로 +1\n",
    "            break\n",
    "    \n",
    "    print(f\"📊 {lang.upper()} 토큰 통계\")\n",
    "    print(f\"- 전체 토큰 수 (중복 포함): {total_freq}\")\n",
    "    print(f\"- 고유 토큰 수: {len(counter)}\")\n",
    "    print(f\"- 상위 {coverage*100:.0f}% 빈도를 커버하는 토큰 수: {cutoff}\")\n",
    "    \n",
    "    return cutoff\n",
    "\n",
    "# 전처리 및 토크나이즈\n",
    "all_ko_tokens = []\n",
    "all_en_tokens = []\n",
    "\n",
    "for text in df['원문']:\n",
    "    processed = preprocess_text(str(text), lang=\"ko\")\n",
    "    all_ko_tokens.extend(ko_tokenizer.tokenize(processed))\n",
    "\n",
    "for text in df['번역문']:\n",
    "    processed = preprocess_text(str(text), lang=\"en\")\n",
    "    all_en_tokens.extend(en_tokenizer.tokenize(processed))\n",
    "\n",
    "# 상위 95% 커버리지 vocab size 계산\n",
    "ko_vocab_cutoff = compute_vocab_cutoff(all_ko_tokens, coverage=0.95, lang=\"ko\")\n",
    "en_vocab_cutoff = compute_vocab_cutoff(all_en_tokens, coverage=0.95, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
